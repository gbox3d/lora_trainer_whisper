# test_run_ct2.py
from faster_whisper import WhisperModel
import time

# λ³€ν™λ λ¨λΈ κ²½λ΅
model_path = "outputs/ct2_small"
# ν…μ¤νΈν•  μ¤λ””μ¤ νμΌ (κ²½λ΅ μμ • ν•„μ”)
audio_path = "datasets/Sample/wav/SPK014/SPK014KBSCU001/SPK014KBSCU001F001.wav" 

print(f"π€ Loading CT2 Model from {model_path}...")
# device="cuda"λ΅ μ„¤μ •ν•λ©΄ GPU μ‚¬μ©
model = WhisperModel(model_path, device="cuda", compute_type="float16")

print("π¤ Transcribing...")
start = time.time()

segments, info = model.transcribe(audio_path, language="ko", beam_size=5)

print(f"\n[Detected Language]: {info.language} (Probability: {info.language_probability:.2f})")
print("-" * 30)

full_text = ""
for segment in segments:
    print(f"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
    full_text += segment.text

print("-" * 30)
end = time.time()
print(f"β… Total Time: {end - start:.4f} sec")