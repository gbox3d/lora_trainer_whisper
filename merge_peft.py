# merge_peft.py
import torch
from transformers import WhisperForConditionalGeneration, WhisperProcessor
from peft import PeftModel

# ê²½ë¡œ ì„¤ì •
BASE_MODEL = "openai/whisper-small"
LORA_DIR = "outputs/small_lora"
MERGED_DIR = "outputs/merged_small"

print(f"â³ Loading Base Model: {BASE_MODEL}")
base_model = WhisperForConditionalGeneration.from_pretrained(BASE_MODEL)
processor = WhisperProcessor.from_pretrained(BASE_MODEL)

print(f"â³ Loading LoRA Adapter: {LORA_DIR}")
model = PeftModel.from_pretrained(base_model, LORA_DIR)

print("âš¡ Merging LoRA into Base Model...")
# í•µì‹¬: LoRA ê°€ì¤‘ì¹˜ë¥¼ ë² ì´ìŠ¤ ëª¨ë¸ì— ì˜êµ¬ì ìœ¼ë¡œ í•©ì¹¨
model = model.merge_and_unload()

print(f"ğŸ’¾ Saving merged model to: {MERGED_DIR}")
model.save_pretrained(MERGED_DIR)
processor.save_pretrained(MERGED_DIR)

print("âœ… Merge Complete!")